{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earned-newsletter",
   "metadata": {},
   "source": [
    "## Junge Freiheit\n",
    "#### Code for scraping Junge Freiheit\n",
    "- https://jungefreiheit.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "opening-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "advisory-fancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "# Using two keywords (\"migraten\" and \"flüchtling\") this time because this is a smaller newspaper with less articles\n",
    "search_f = '/?s=fl%C3%BCchtling'\n",
    "base_url = 'https://jungefreiheit.de/page/'\n",
    "n = 2 # I started at 2 because the structure of the url is different for page 1 and there is no reason I would need\n",
    "# it searching for 2015\n",
    "\n",
    "#Compile urls \n",
    "urls_f = []\n",
    "while n <= 39:\n",
    "    url_f = base_url+str(n)+search_f\n",
    "    n += 1\n",
    "    urls_f.append(url_f)\n",
    "    \n",
    "print(len(urls_f))\n",
    "\n",
    "# Search using keyword: Migranten\n",
    "search_m = '/?s=migranten'\n",
    "urls_m = []\n",
    "m = 2\n",
    "while m <= 149:\n",
    "    url_m = base_url+str(m)+search_m\n",
    "    m += 1\n",
    "    urls_m.append(url_m)\n",
    "    \n",
    "print(len(urls_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "comfortable-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "#Create one list of urls\n",
    "urls = urls_m +urls_f\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stuffed-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the urls of the pages of articles and if the date is 2015 get the links for the relevent articles\n",
    "\n",
    "art_links = []\n",
    "date = []\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    d = soup.find(\"span\", {\"class\":\"elementor-post-date\"})\n",
    "    if d.text[-6:-2]=='2015':\n",
    "        date.append(d.text)\n",
    "        divs = soup.find_all(\"div\", {\"class\":\"elementor-post__text\"})\n",
    "        for div in divs:\n",
    "            a = div.find('a')\n",
    "            art_links.append(a.get('href'))\n",
    "            \n",
    "        \n",
    "#art_links                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "friendly-university",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a little sparse, but it is a smaller weekly newspaper\n",
    "len(art_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "recent-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each link and get the date and text and append to a dictionary\n",
    "date_dict = {}\n",
    "art_dict_jf = {}\n",
    "x = ' '\n",
    "for link in art_links:\n",
    "    page = urllib.request.urlopen(link)\n",
    "    soup = BeautifulSoup(page)\n",
    "    t = soup.find(\"div\", {\"class\":\"elementor-widget-theme-post-content\"})\n",
    "    #print(t)\n",
    "    paras = t.findAll('p')\n",
    "    a = [p.text for p in paras]\n",
    "    d = soup.find(\"span\", {\"class\":\"elementor-icon-list-text elementor-post-info__item elementor-post-info__item--type-date\"})\n",
    "    text = x.join(a)\n",
    "    date_dict[link] = d.text\n",
    "    art_dict_jf[link] = text\n",
    "    #print(text)\n",
    "    \n",
    "#art_dict_jf\n",
    "#date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acceptable-arbitration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I guess there were 3 duplicates\n",
    "len(art_dict_jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "governing-application",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>POTSDAM. Brandenburgs AfD-Chef Alexander Gaula...</td>\n",
       "      <td>385</td>\n",
       "      <td>18. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://jungefreiheit.de/debatte/kommentar/201...</td>\n",
       "      <td>Die Norwegerin Linda Hagen ist immer noch ganz...</td>\n",
       "      <td>171</td>\n",
       "      <td>05. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>ERFURT. Asylbewerber, die mit der Deutschen Ba...</td>\n",
       "      <td>191</td>\n",
       "      <td>04. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://jungefreiheit.de/politik/ausland/2015/...</td>\n",
       "      <td>TRIPOLIS. Der libysche „Allgemeine Volkskongre...</td>\n",
       "      <td>262</td>\n",
       "      <td>04. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>Dreizehn Regierungschefs beschließen auf einem...</td>\n",
       "      <td>729</td>\n",
       "      <td>01. November 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href  \\\n",
       "0  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "1  https://jungefreiheit.de/debatte/kommentar/201...   \n",
       "2  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "3  https://jungefreiheit.de/politik/ausland/2015/...   \n",
       "4  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "\n",
       "                                                text  word_count  \\\n",
       "0  POTSDAM. Brandenburgs AfD-Chef Alexander Gaula...         385   \n",
       "1  Die Norwegerin Linda Hagen ist immer noch ganz...         171   \n",
       "2  ERFURT. Asylbewerber, die mit der Deutschen Ba...         191   \n",
       "3  TRIPOLIS. Der libysche „Allgemeine Volkskongre...         262   \n",
       "4  Dreizehn Regierungschefs beschließen auf einem...         729   \n",
       "\n",
       "                date  \n",
       "0  18. November 2015  \n",
       "1  05. November 2015  \n",
       "2  04. November 2015  \n",
       "3  04. November 2015  \n",
       "4  01. November 2015  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jf = pd.DataFrame.from_dict(art_dict_jf, orient='index')\n",
    "df_jf.reset_index(inplace=True)\n",
    "df_jf.columns = ['href', 'text']\n",
    "word_c = df_jf.text.str.split().map(len)\n",
    "df_jf['word_count'] = word_c\n",
    "\n",
    "df_jf['date']= df_jf['href'].map(date_dict)\n",
    "\n",
    "df_jf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "accomplished-mention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   href        60 non-null     object\n",
      " 1   text        60 non-null     object\n",
      " 2   word_count  60 non-null     int64 \n",
      " 3   date        60 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_jf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "baking-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling\n",
    "pd.to_pickle(df_jf, \"jf_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
