{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-window",
   "metadata": {},
   "source": [
    "## Flüchtlingskrise Sentiment Analysis\n",
    "### Emily Martin, eem80@pitt.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "handy-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-injection",
   "metadata": {},
   "source": [
    "## The data\n",
    "#### Shape and acquisition\n",
    "- Using the four scripts in my repo: [Süddeutsche_zeitung](https://github.com/Data-Science-for-Linguists-2021/Fluechtlingskrise-Sentiment-Analysis/blob/main/Süddeutsche_zeitung.ipynb), [taz](https://github.com/Data-Science-for-Linguists-2021/Fluechtlingskrise-Sentiment-Analysis/blob/main/taz.ipynb), [zeit](https://github.com/Data-Science-for-Linguists-2021/Fluechtlingskrise-Sentiment-Analysis/blob/main/zeit.ipynb) and [Junge Freiheit](https://github.com/Data-Science-for-Linguists-2021/Fluechtlingskrise-Sentiment-Analysis/blob/main/Junge%20Freiheit.ipynb) I was able to scrape the sites for news articles from 2015 using the search terms 'Flüchtling' (refugee) and/or 'Migranten' (migrants). \n",
    "- The actual number of articles varies widely per site because of ease of scraping and simply overall newspaper size. For Die TAZ there are 100 articles, from manually compiled links, for  Der Zeit there are 573, from links collected through their API, for Der Süddeutsche Zeitung there are 982 and for Junge Freiheit there are 60. \n",
    "- After collecting these articles in the scripts I made them into dataframes which I then pickled. However these pickled files are not available through my repo due to copywrite.\n",
    "\n",
    "### A quick look at each source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-donor",
   "metadata": {},
   "source": [
    "#### Der Zeit\n",
    "- Der Zeit is one of the largest weekly newspapers in Germany, it is centrist/liberal in its political leanings and kindly supports an API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fancy-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>release_date</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahmood im Schilderwald</td>\n",
       "      <td>http://www.zeit.de/2015/51/fuehrerschein-fluec...</td>\n",
       "      <td>Als er vor über zehn Jahren Autofahren gelernt...</td>\n",
       "      <td>2015-12-31T02:51:37Z</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zwei zähe Einzelgänger</td>\n",
       "      <td>http://www.zeit.de/2015/51/vorbereitung-auf-da...</td>\n",
       "      <td>Wo Zou Lei herkommt, ist das Leben nicht leich...</td>\n",
       "      <td>2015-12-31T01:56:01Z</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fortsetzung folgt – jetzt</td>\n",
       "      <td>http://www.zeit.de/2016/01/geschichten-2015-fo...</td>\n",
       "      <td>Lok Leipzig ist ratlos, was aus Mario Basler w...</td>\n",
       "      <td>2015-12-30T09:00:08Z</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anhaltend hohe Flüchtlingszahlen auf Balkanroute</td>\n",
       "      <td>http://www.zeit.de/gesellschaft/2015-12/slowen...</td>\n",
       "      <td>Auch zum Jahresende kommen weiter täglich Taus...</td>\n",
       "      <td>2015-12-29T22:14:02Z</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laut Özoğuz schürt Union Vorurteile gegen Flüc...</td>\n",
       "      <td>http://www.zeit.de/politik/deutschland/2015-12...</td>\n",
       "      <td>Opposition und Koalitionspartner kritisieren d...</td>\n",
       "      <td>2015-12-29T08:24:55Z</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                            Mahmood im Schilderwald   \n",
       "1                             Zwei zähe Einzelgänger   \n",
       "2                          Fortsetzung folgt – jetzt   \n",
       "3   Anhaltend hohe Flüchtlingszahlen auf Balkanroute   \n",
       "4  Laut Özoğuz schürt Union Vorurteile gegen Flüc...   \n",
       "\n",
       "                                                href  \\\n",
       "0  http://www.zeit.de/2015/51/fuehrerschein-fluec...   \n",
       "1  http://www.zeit.de/2015/51/vorbereitung-auf-da...   \n",
       "2  http://www.zeit.de/2016/01/geschichten-2015-fo...   \n",
       "3  http://www.zeit.de/gesellschaft/2015-12/slowen...   \n",
       "4  http://www.zeit.de/politik/deutschland/2015-12...   \n",
       "\n",
       "                                                text          release_date  \\\n",
       "0  Als er vor über zehn Jahren Autofahren gelernt...  2015-12-31T02:51:37Z   \n",
       "1  Wo Zou Lei herkommt, ist das Leben nicht leich...  2015-12-31T01:56:01Z   \n",
       "2  Lok Leipzig ist ratlos, was aus Mario Basler w...  2015-12-30T09:00:08Z   \n",
       "3  Auch zum Jahresende kommen weiter täglich Taus...  2015-12-29T22:14:02Z   \n",
       "4  Opposition und Koalitionspartner kritisieren d...  2015-12-29T08:24:55Z   \n",
       "\n",
       "   word_count  \n",
       "0        1175  \n",
       "1        1125  \n",
       "2         313  \n",
       "3         362  \n",
       "4         379  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle the dataframes\n",
    "zeit_df = pd.read_pickle(\"zeit_df.pkl\")\n",
    "\n",
    "print(zeit_df.shape)\n",
    "zeit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "electoral-herald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573 entries, 0 to 572\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         573 non-null    object\n",
      " 1   href          573 non-null    object\n",
      " 2   text          573 non-null    object\n",
      " 3   release_date  573 non-null    object\n",
      " 4   word_count    573 non-null    int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# A little about this dataframe:\n",
    "zeit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "professional-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.750436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>237.382328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>551.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>697.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1945.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count\n",
       "count   573.000000\n",
       "mean    562.750436\n",
       "std     237.382328\n",
       "min       1.000000\n",
       "25%     384.000000\n",
       "50%     551.000000\n",
       "75%     697.000000\n",
       "max    1945.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeit_df.describe()\n",
    "# min of 1, there is at least one article where the link was broken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-armor",
   "metadata": {},
   "source": [
    "### Die TAZ\n",
    "-  Die TAZ (Die Tageszeitung) is a daily German newspaper with a modest circulation, it leans left-wing/green and is the most left-ist of the sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "characteristic-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://taz.de/Essay-Journalismus-und-Zuwander...</td>\n",
       "      <td>Deutschland hat sich verändert. Die Redaktione...</td>\n",
       "      <td>1232</td>\n",
       "      <td>2015-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://taz.de/Fluechtlingsdebatte-in-den-USA/...</td>\n",
       "      <td>Nach den Anschlägen von Paris wollen nur noch ...</td>\n",
       "      <td>786</td>\n",
       "      <td>2015-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://taz.de/Kommentar-Verfassungsschutz/!50...</td>\n",
       "      <td>Die Reform des V-Leute-Wesens ist eine Charmeo...</td>\n",
       "      <td>266</td>\n",
       "      <td>2015-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://taz.de/NPD-Invasion-in-Fluechtlingsunt...</td>\n",
       "      <td>NPD-Landtagsabgeordnete besuchten eine Erstauf...</td>\n",
       "      <td>561</td>\n",
       "      <td>2015-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://taz.de/Misshandlung-von-Fluechtlingen-...</td>\n",
       "      <td>Per Referendum will Premier Orbán rechtswidrig...</td>\n",
       "      <td>471</td>\n",
       "      <td>2015-04-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href  \\\n",
       "0  https://taz.de/Essay-Journalismus-und-Zuwander...   \n",
       "1  https://taz.de/Fluechtlingsdebatte-in-den-USA/...   \n",
       "2  https://taz.de/Kommentar-Verfassungsschutz/!50...   \n",
       "3  https://taz.de/NPD-Invasion-in-Fluechtlingsunt...   \n",
       "4  https://taz.de/Misshandlung-von-Fluechtlingen-...   \n",
       "\n",
       "                                                text  word_count        date  \n",
       "0  Deutschland hat sich verändert. Die Redaktione...        1232  2015-12-31  \n",
       "1  Nach den Anschlägen von Paris wollen nur noch ...         786  2015-11-17  \n",
       "2  Die Reform des V-Leute-Wesens ist eine Charmeo...         266  2015-03-25  \n",
       "3  NPD-Landtagsabgeordnete besuchten eine Erstauf...         561  2015-09-28  \n",
       "4  Per Referendum will Premier Orbán rechtswidrig...         471  2015-04-28  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle and a quick look at the dataframe\n",
    "taz_df = pd.read_pickle(\"taz_df.pkl\")\n",
    "print(taz_df.shape)\n",
    "taz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "latest-penguin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   href        100 non-null    object\n",
      " 1   text        100 non-null    object\n",
      " 2   word_count  100 non-null    int64 \n",
      " 3   date        100 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "taz_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "married-mentor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>799.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>458.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>674.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2846.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count\n",
       "count   100.000000\n",
       "mean    799.430000\n",
       "std     458.021332\n",
       "min     209.000000\n",
       "25%     495.000000\n",
       "50%     674.000000\n",
       "75%     948.000000\n",
       "max    2846.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taz_df.describe()\n",
    "# No broken links/problem areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-space",
   "metadata": {},
   "source": [
    "### Der Süddeutsche Zeitung\n",
    "- Der Süddeustche Zeitung is a daily newspaper with a very wide ciruclation (second largest after Der Zeit), it leans left-liberal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "intense-companion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.sueddeutsche.de/politik/migration-...</td>\n",
       "      <td>Berlin (dpa) - Die Bundesländer haben für die ...</td>\n",
       "      <td>89</td>\n",
       "      <td>27. Dezember 2015, 2:45 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.sueddeutsche.de/politik/migration-...</td>\n",
       "      <td>Rom (dpa) - Im Mittelmeer vor Italien sind auc...</td>\n",
       "      <td>62</td>\n",
       "      <td>26. Dezember 2015, 20:51 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.sueddeutsche.de/kultur/rueckblick-...</td>\n",
       "      <td>1 / 12 Quelle: 20th Century Fox Südseefilme si...</td>\n",
       "      <td>1818</td>\n",
       "      <td>26. Dezember 2015, 17:57 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.sueddeutsche.de/politik/rueckblick...</td>\n",
       "      <td>Bei dem Blick zurück auf das Jahr 2015 stechen...</td>\n",
       "      <td>451</td>\n",
       "      <td>26. Dezember 2015, 16:00 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.sueddeutsche.de/politik/fluechtlin...</td>\n",
       "      <td>Nach einem Brandanschlag auf eine noch nicht f...</td>\n",
       "      <td>387</td>\n",
       "      <td>26. Dezember 2015, 15:43 Uhr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href  \\\n",
       "0  https://www.sueddeutsche.de/politik/migration-...   \n",
       "1  https://www.sueddeutsche.de/politik/migration-...   \n",
       "2  https://www.sueddeutsche.de/kultur/rueckblick-...   \n",
       "3  https://www.sueddeutsche.de/politik/rueckblick...   \n",
       "4  https://www.sueddeutsche.de/politik/fluechtlin...   \n",
       "\n",
       "                                                text  word_count  \\\n",
       "0  Berlin (dpa) - Die Bundesländer haben für die ...          89   \n",
       "1  Rom (dpa) - Im Mittelmeer vor Italien sind auc...          62   \n",
       "2  1 / 12 Quelle: 20th Century Fox Südseefilme si...        1818   \n",
       "3  Bei dem Blick zurück auf das Jahr 2015 stechen...         451   \n",
       "4  Nach einem Brandanschlag auf eine noch nicht f...         387   \n",
       "\n",
       "                           date  \n",
       "0   27. Dezember 2015, 2:45 Uhr  \n",
       "1  26. Dezember 2015, 20:51 Uhr  \n",
       "2  26. Dezember 2015, 17:57 Uhr  \n",
       "3  26. Dezember 2015, 16:00 Uhr  \n",
       "4  26. Dezember 2015, 15:43 Uhr  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle and aa quick look at the data\n",
    "sz_df = pd.read_pickle(\"sz_df.pkl\")\n",
    "print(sz_df.shape)\n",
    "sz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "round-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   href        1000 non-null   object\n",
      " 1   text        1000 non-null   object\n",
      " 2   word_count  1000 non-null   int64 \n",
      " 3   date        982 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sz_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "standing-immigration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>368.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>282.050192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>331.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>532.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2402.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count\n",
       "count  1000.000000\n",
       "mean    368.440000\n",
       "std     282.050192\n",
       "min       1.000000\n",
       "25%     119.000000\n",
       "50%     331.500000\n",
       "75%     532.250000\n",
       "max    2402.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz_df.describe()\n",
    "# There were 18 broken links\n",
    "# Fairly short articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-direction",
   "metadata": {},
   "source": [
    "### Junge Freiheit\n",
    "-  Junge Freiheit is a small weekly newspaper with fairly strong right-wing leanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "current-malaysia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>POTSDAM. Brandenburgs AfD-Chef Alexander Gaula...</td>\n",
       "      <td>385</td>\n",
       "      <td>18. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://jungefreiheit.de/debatte/kommentar/201...</td>\n",
       "      <td>Die Norwegerin Linda Hagen ist immer noch ganz...</td>\n",
       "      <td>171</td>\n",
       "      <td>05. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>ERFURT. Asylbewerber, die mit der Deutschen Ba...</td>\n",
       "      <td>191</td>\n",
       "      <td>04. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://jungefreiheit.de/politik/ausland/2015/...</td>\n",
       "      <td>TRIPOLIS. Der libysche „Allgemeine Volkskongre...</td>\n",
       "      <td>262</td>\n",
       "      <td>04. November 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>Dreizehn Regierungschefs beschließen auf einem...</td>\n",
       "      <td>729</td>\n",
       "      <td>01. November 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href  \\\n",
       "0  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "1  https://jungefreiheit.de/debatte/kommentar/201...   \n",
       "2  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "3  https://jungefreiheit.de/politik/ausland/2015/...   \n",
       "4  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "\n",
       "                                                text  word_count  \\\n",
       "0  POTSDAM. Brandenburgs AfD-Chef Alexander Gaula...         385   \n",
       "1  Die Norwegerin Linda Hagen ist immer noch ganz...         171   \n",
       "2  ERFURT. Asylbewerber, die mit der Deutschen Ba...         191   \n",
       "3  TRIPOLIS. Der libysche „Allgemeine Volkskongre...         262   \n",
       "4  Dreizehn Regierungschefs beschließen auf einem...         729   \n",
       "\n",
       "                date  \n",
       "0  18. November 2015  \n",
       "1  05. November 2015  \n",
       "2  04. November 2015  \n",
       "3  04. November 2015  \n",
       "4  01. November 2015  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle and a quick look at the data\n",
    "jf_df = pd.read_pickle(\"jf_df.pkl\")\n",
    "print(jf_df.shape) # This is the smallest sample\n",
    "jf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "spread-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   href        60 non-null     object\n",
      " 1   text        60 non-null     object\n",
      " 2   word_count  60 non-null     int64 \n",
      " 3   date        60 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "jf_df.info()\n",
    "# All non-null, which is good. Can't really afford to lose more articles from this source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "blond-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>461.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>323.277373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>195.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>732.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1348.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count\n",
       "count    60.000000\n",
       "mean    461.666667\n",
       "std     323.277373\n",
       "min     126.000000\n",
       "25%     195.250000\n",
       "50%     356.000000\n",
       "75%     732.750000\n",
       "max    1348.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-reception",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "domestic-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# Prepare data: remove stop words\n",
    "\n",
    "# Lemmatization (seems better than stemming)?\n",
    "# SpaCy has a german lemmetizer (and ger stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More notes (3/31): Make a spacy pipeline with sentiments analysis as part of it? (how to use sentiws and how \n",
    "# to loop through a list of the texts from each array - figure it out!)\n",
    "\n",
    "# Or: Use SpaCy for tokenization, lemmatization, removing stop words by creating custom functions? Look into both \n",
    "# options. \n",
    "# I definitely need to get something with labels, so sentiws seems good\n",
    "# Much to do...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "optimum-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = zeit_df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "maritime-pixel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fixed-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Als als\n",
      "er ich\n",
      "vor vor\n",
      "über über\n",
      "zehn zehn\n",
      "Jahren Jahr\n",
      "Autofahren Autofahren\n",
      "gelernt lernen\n",
      "hat haben\n",
      ", ,\n",
      "brauchte brauchen\n",
      "Mahmood Mahmood\n",
      "\n",
      "       \n",
      "      \n",
      "Shaker Shaker\n",
      "keinen kein\n",
      "Führerschein Führerschein\n",
      ". .\n",
      "Wozu wozu\n",
      "auch auch\n",
      "? ?\n",
      "In In\n",
      "seiner sich\n",
      "Heimat Heimat\n",
      "Irak Irak\n",
      "hat haben\n",
      "ihn ich\n",
      "nie nie\n",
      "jemand jemand\n",
      "nach nach\n",
      "einer einer\n",
      "\n",
      "       \n",
      "      \n",
      "Fahrerlaubnis Fahrerlaubnis\n",
      "gefragt fragen\n",
      ", ,\n",
      "nicht nicht\n",
      "mal mal\n",
      "der der\n",
      "Polizist Polizist\n",
      ", ,\n",
      "der der\n",
      "ihn ich\n",
      "einmal einmal\n",
      "angehalten anhalten\n",
      "hat haben\n",
      ". .\n",
      "Verkehrsregeln Verkehrsregeln\n",
      "\n",
      "       \n",
      "      \n",
      "gebe geben\n",
      "es ich\n",
      "zwar zwar\n",
      ", ,\n",
      "aber aber\n",
      "kaum kaum\n",
      "jemand jemand\n",
      "halte halte\n",
      "sich sich\n",
      "daran daran\n",
      ". .\n",
      "\" \"\n",
      "Dem der\n",
      "Nachbarn Nachbar\n",
      "lässt lässt\n",
      "man man\n",
      "die der\n",
      "Vorfahrt Vorfahrt\n",
      ", ,\n",
      "einem einer\n",
      "\n",
      "       \n",
      "      \n",
      "Fremden Fremde\n",
      "nicht nicht\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "Shaker Shaker\n",
      ". .\n",
      "Schilder Schilder\n",
      "dienten dienen\n",
      "nur nur\n",
      "als als\n",
      "grobe grobe\n",
      "Orientierung Orientierung\n",
      ", ,\n",
      "die der\n",
      "Ampeln Ampel\n",
      "seien sein\n",
      "\n",
      "       \n",
      "      \n",
      "fast fast\n",
      "immer immer\n",
      "kaputt kaputt\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "In In\n",
      "Bielefeld Bielefeld\n",
      "sieht sehen\n",
      "das der\n",
      "etwas etwas\n",
      "anders anders\n",
      "aus aus\n",
      ". .\n",
      "Hier Hier\n",
      "ist sein\n",
      "der der\n",
      "29-jährige 29-jährige\n",
      "Iraker Iraker\n",
      "nach nach\n",
      "seinem mein\n",
      "Studium Studium\n",
      "in in\n",
      "der der\n",
      "Ukraine Ukraine\n",
      "angekommen ankommen\n",
      ". .\n",
      "In In\n",
      "den der\n",
      "Irak Irak\n",
      "traute trauen\n",
      "er ich\n",
      "sich sich\n",
      "nicht nicht\n",
      "mehr mehr\n",
      "zurück zurück\n",
      ". .\n",
      "Jetzt Jetzt\n",
      "sitzt sitzen\n",
      "er ich\n",
      "im im\n",
      "friedlichen friedlich\n",
      "Westfalen Westfale\n",
      "wieder wieder\n",
      "am am\n",
      "Steuer Steuer\n",
      ". .\n",
      "Neben Neben\n",
      "ihm ich\n",
      "allerdings allerdings\n",
      "bremst bremsen\n",
      "Fahrlehrer Fahrlehrer\n",
      "Dirk Dirk\n",
      "Konert Konert\n",
      "zur zur\n",
      "Not Not\n",
      "mit mit\n",
      ". .\n",
      "Shaker Shaker\n",
      "will wollen\n",
      "die der\n",
      "deutsche deutsch\n",
      "Führerscheinprüfung Führerscheinprüfung\n",
      "bestehen bestehen\n",
      ". .\n",
      "Der der\n",
      "Mediziner Mediziner\n",
      "hofft hoffen\n",
      "hier hier\n",
      "als als\n",
      "Landarzt Landarzt\n",
      "arbeiten arbeiten\n",
      "zu zu\n",
      "können können\n",
      ". .\n",
      "\" \"\n",
      "Ohne ohne\n",
      "Führerschein Führerschein\n",
      "ist sein\n",
      "das der\n",
      "undenkbar undenkbar\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "er ich\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Hunderttausende Hunderttausende\n",
      "Flüchtlinge Flüchtling\n",
      "wollen wollen\n",
      "bald bald\n",
      "wieder wieder\n",
      "ihrem mein\n",
      "Beruf Beruf\n",
      "nachgehen nachgehen\n",
      ". .\n",
      "Zu zu\n",
      "all all\n",
      "den der\n",
      "Hürden Hürde\n",
      "der der\n",
      "Asylanträge Asylanträge\n",
      "und und\n",
      "der der\n",
      "Sprache Sprache\n",
      "kommt kommen\n",
      "für für\n",
      "viele viel\n",
      "die der\n",
      "fehlende fehlend\n",
      "Fahrerlaubnis Fahrerlaubnis\n",
      "hinzu hinzu\n",
      ". .\n",
      "Hier Hier\n",
      "entstehen entstehen\n",
      "hohe hoch\n",
      "Kosten Kosten\n",
      ", ,\n",
      "selbst selbst\n",
      "für für\n",
      "jene jen\n",
      "Flüchtlinge Flüchtling\n",
      ", ,\n",
      "die der\n",
      "– –\n",
      "anders anders\n",
      "als als\n",
      "Shaker Shaker\n",
      "– –\n",
      "schon schon\n",
      "einen ein\n",
      "Führerschein Führerschein\n",
      "besitzen besitzen\n",
      ". .\n",
      "Denn denn\n",
      "Fahrerlaubnisse Fahrerlaubnis\n",
      "aus aus\n",
      "den der\n",
      "typischen typisch\n",
      "Herkunftsländern Herkunftsländern\n",
      "wie wie\n",
      "Syrien Syrien\n",
      ", ,\n",
      "Afghanistan Afghanistan\n",
      "oder oder\n",
      "dem der\n",
      "Irak Irak\n",
      "werden werden\n",
      "in in\n",
      "Deutschland Deutschland\n",
      "nur nur\n",
      "für für\n",
      "sechs sechs\n",
      "Monate Monat\n",
      "nach nach\n",
      "einer einer\n",
      "\" \"\n",
      "Touristenregelung Touristenregelung\n",
      "\" \"\n",
      "anerkannt anerkennen\n",
      ". .\n",
      "Für Für\n",
      "eine einen\n",
      "Umschreibung Umschreibung\n",
      "ist sein\n",
      "dann dann\n",
      "eine einen\n",
      "theoretische theoretische\n",
      "und und\n",
      "praktische praktische\n",
      "Prüfung Prüfung\n",
      "vonnöten vonnöten\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Früher Früher\n",
      "kurvte kurven\n",
      "Mahmood Mahmood\n",
      "Shaker Shaker\n",
      "regelmäßig regelmäßig\n",
      "durch durch\n",
      "die der\n",
      "wuseligen wuselig\n",
      "Straßen Straße\n",
      "im im\n",
      "irakischen irakisch\n",
      "Haditha Haditha\n",
      ", ,\n",
      "seine mein\n",
      "Eltern Eltern\n",
      "brachten bringen\n",
      "ihm ich\n",
      "die der\n",
      "wichtigsten wichtig\n",
      "Handgriffe Handgriffe\n",
      "und und\n",
      "Regeln Regel\n",
      "bei bei\n",
      ". .\n",
      "Nun Nun\n",
      "fixieren fixieren\n",
      "seine mein\n",
      "Augen Auge\n",
      "abwechselnd abwechseln\n",
      "die der\n",
      "Straße Straße\n",
      "und und\n",
      "die der\n",
      "Spiegel Spiegel\n",
      ", ,\n",
      "beide beid\n",
      "Hände Hand\n",
      "umklammern umklammern\n",
      "fest fest\n",
      "das der\n",
      "Lenkrad Lenkrad\n",
      ". .\n",
      "\" \"\n",
      "Siehst Siehst\n",
      "du du\n",
      "dieses dies\n",
      "blaue blau\n",
      "Schild Schild\n",
      "mit mit\n",
      "dem der\n",
      "Pfeil Pfeil\n",
      "? ?\n",
      "\" \"\n",
      ", ,\n",
      "fragt fragen\n",
      "Fahrlehrer Fahrlehrer\n",
      "Konert Konert\n",
      ". .\n",
      "\" \"\n",
      "Hier Hier\n",
      "ist sein\n",
      "vorgeschrieben vorschreiben\n",
      ", ,\n",
      "rechts rechts\n",
      "abzubiegen abbiegen\n",
      ". .\n",
      "\" \"\n",
      "Sein mein\n",
      "Schüler Schüler\n",
      "nickt nicken\n",
      ". .\n",
      "Mahmood Mahmood\n",
      "Shaker Shaker\n",
      "wirkt wirken\n",
      "sehr sehr\n",
      "konzentriert konzentrieren\n",
      ", ,\n",
      "sagt sagen\n",
      "während während\n",
      "der der\n",
      "Fahrt Fahrt\n",
      "kein kein\n",
      "Wort Wort\n",
      ". .\n",
      "Es ich\n",
      "ist sein\n",
      "seine mein\n",
      "zweite zweite\n",
      "Fahrstunde Fahrstunde\n",
      ". .\n",
      "Anstrengend Anstrengend\n",
      "sei sein\n",
      "das der\n",
      "Fahren Fahren\n",
      "in in\n",
      "Deutschland Deutschland\n",
      ", ,\n",
      "sagt sagen\n",
      "er ich\n",
      "später spät\n",
      ", ,\n",
      "die der\n",
      "vielen viel\n",
      "Schilder Schilder\n",
      ", ,\n",
      "die der\n",
      "strengen streng\n",
      "Regeln Regel\n",
      ". .\n",
      "Im Im\n",
      "Irak Irak\n",
      "dagegen dagegen\n",
      "gelte gelten\n",
      "es ich\n",
      ", ,\n",
      "möglichst möglichst\n",
      "schnell schnellen\n",
      "auf auf\n",
      "das der\n",
      "Verhalten Verhalten\n",
      "anderer ander\n",
      "Fahrer Fahrer\n",
      "zu zu\n",
      "reagieren reagieren\n",
      "– –\n",
      "eine einen\n",
      "ganz ganz\n",
      "andere ander\n",
      "Herangehensweise Herangehensweise\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Für Für\n",
      "die der\n",
      "meisten meist\n",
      "Flüchtlinge Flüchtling\n",
      "ist sein\n",
      "es ich\n",
      "wichtig wichtig\n",
      ", ,\n",
      "erst erst\n",
      "einmal einmal\n",
      "ein einen\n",
      "Dach Dach\n",
      "über über\n",
      "dem der\n",
      "Kopf Kopf\n",
      "zu zu\n",
      "haben haben\n",
      ". .\n",
      "Aber aber\n",
      "was was\n",
      "kommt kommen\n",
      "dann dann\n",
      "? ?\n",
      "Gerhard Gerhard\n",
      "von von\n",
      "Bressensdorf Bressensdorf\n",
      ", ,\n",
      "Vorsitzender Vorsitzender\n",
      "des der\n",
      "deutschen deutsch\n",
      "Fahrlehrerverbandes Fahrlehrerverbandes\n",
      ", ,\n",
      "rechnet rechnen\n",
      "fest fest\n",
      "mit mit\n",
      "steigender steigend\n",
      "Fahrstundennachfrage Fahrstundennachfrage\n",
      "von von\n",
      "Flüchtlingen Flüchtling\n",
      ". .\n",
      "\" \"\n",
      "Wer Wer\n",
      "Auto Auto\n",
      "fahren fahren\n",
      "kann können\n",
      ", ,\n",
      "hat haben\n",
      "beruflich beruflich\n",
      "viel viel\n",
      "mehr mehr\n",
      "Chancen Chance\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "er ich\n",
      ". .\n",
      "Tatsächlich Tatsächlich\n",
      "scheinen scheinen\n",
      "Jobs Job\n",
      "wie wie\n",
      "Taxifahrer Taxifahrer\n",
      ", ,\n",
      "Paketzusteller Paketzusteller\n",
      "oder oder\n",
      "Pizzabote Pizzabote\n",
      "für für\n",
      "Migranten Migranten\n",
      "ohne ohne\n",
      "Ausbildung Ausbildung\n",
      "naheliegend naheliegen\n",
      ". .\n",
      "Und und\n",
      "wer wer\n",
      "auf auf\n",
      "dem der\n",
      "Land Land\n",
      "lebe leben\n",
      ", ,\n",
      "sagt sagen\n",
      "von von\n",
      "Bressensdorf Bressensdorf\n",
      ", ,\n",
      "komme kommen\n",
      "ohne ohne\n",
      "Auto Auto\n",
      "oft oft\n",
      "gar gar\n",
      "nicht nicht\n",
      "zur zur\n",
      "Arbeitsstelle Arbeitsstelle\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Das der\n",
      "Deutsche deutschen\n",
      "Rote rot\n",
      "Kreuz Kreuz\n",
      "( (\n",
      "DRK DRK\n",
      ") )\n",
      "in in\n",
      "Bielefeld Bielefeld\n",
      "hat haben\n",
      "den der\n",
      "Bedarf Bedarf\n",
      "früh früh\n",
      "erkannt erkennen\n",
      "– –\n",
      "und und\n",
      "im im\n",
      "Juni Juni\n",
      "eine einen\n",
      "gemeinnützige gemeinnützig\n",
      "Fahrschule Fahrschule\n",
      "gegründet gründen\n",
      ". .\n",
      "Neben Neben\n",
      "DRK-Mitarbeitern DRK-Mitarbeitern\n",
      "und und\n",
      "Senioren Senior\n",
      "sollen sollen\n",
      "hier hier\n",
      "ganz ganz\n",
      "gezielt zielen\n",
      "auch auch\n",
      "Migranten Migranten\n",
      "ausgebildet ausbilden\n",
      "werden werden\n",
      ". .\n",
      "Fünf Fünf\n",
      "Flüchtlinge Flüchtling\n",
      "haben haben\n",
      "sich sich\n",
      "bisher bisher\n",
      "angemeldet anmelden\n",
      ", ,\n",
      "Mahmood Mahmood\n",
      "Shaker Shaker\n",
      "ist sein\n",
      "einer einer\n",
      "von von\n",
      "ihnen ich\n",
      ". .\n",
      "Im Im\n",
      "Sommer Sommer\n",
      "lief laufen\n",
      "er ich\n",
      "zufällig zufällig\n",
      "an an\n",
      "der der\n",
      "neuen neu\n",
      "Fahrschule Fahrschule\n",
      "vorbei vorbei\n",
      ". .\n",
      "Fahrlehrer Fahrlehrer\n",
      "Dirk Dirk\n",
      "Konert Konert\n",
      "setzte setzen\n",
      "sich sich\n",
      "mit mit\n",
      "ihm ich\n",
      "zusammen zusammen\n",
      ", ,\n",
      "ließ lassen\n",
      "sich sich\n",
      "seine mein\n",
      "Geschichte Geschichte\n",
      "erzählen erzählen\n",
      ". .\n",
      "Gemeinsam Gemeinsam\n",
      "kalkulierten kalkulieren\n",
      "die der\n",
      "beiden beid\n",
      "die der\n",
      "Kosten Kosten\n",
      ", ,\n",
      "vereinbarten vereinbart\n",
      "eine einen\n",
      "Schnupperstunde Schnupperstunde\n",
      ". .\n",
      "\" \"\n",
      "Das der\n",
      "kann können\n",
      "eine einen\n",
      "kommerzielle kommerzielle\n",
      "Fahrschule Fahrschule\n",
      "nicht nicht\n",
      "bieten bieten\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "Konert Konert\n",
      ". .\n",
      "Dort Dort\n",
      "sei sein\n",
      "normalerweise normalerweise\n",
      "direkt direkt\n",
      "die der\n",
      "erste erste\n",
      "Grundgebühr Grundgebühr\n",
      "fällig fällig\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Auch Auch\n",
      "weitere weit\n",
      "Hürden Hürde\n",
      "räumt räumen\n",
      "die der\n",
      "Fahrschule Fahrschule\n",
      "aus aus\n",
      "dem der\n",
      "Weg Weg\n",
      ". .\n",
      "Dolmetscher Dolmetscher\n",
      "übersetzen übersetzen\n",
      ", ,\n",
      "wenn wenn\n",
      "nötig nötigen\n",
      ", ,\n",
      "den der\n",
      "Theorieunterricht Theorieunterricht\n",
      ". .\n",
      "Ebenso Ebenso\n",
      "angedacht andenken\n",
      "ist sein\n",
      "ein einen\n",
      "spezielles speziell\n",
      "Arabisch-Wörterbuch Arabisch-Wörterbuch\n",
      "mit mit\n",
      "Begriffen Begriff\n",
      "aus aus\n",
      "der der\n",
      "Fahrschule Fahrschule\n",
      ": :\n",
      "Blinker Blinker\n",
      ", ,\n",
      "Stoppschild Stoppschild\n",
      ", ,\n",
      "Sackgasse Sackgasse\n",
      ". .\n",
      "Weibliche weiblich\n",
      "Flüchtlinge Flüchtling\n",
      ", ,\n",
      "die der\n",
      "aus aus\n",
      "religiösen religiös\n",
      "Gründen Grund\n",
      "nicht nicht\n",
      "allein allein\n",
      "mit mit\n",
      "einem einer\n",
      "Mann Mann\n",
      "im im\n",
      "Auto Auto\n",
      "sitzen sitzen\n",
      "möchten mögen\n",
      ", ,\n",
      "fahren fahren\n",
      "mit mit\n",
      "einer einer\n",
      "Fahrlehrerin Fahrlehrerin\n",
      ". .\n",
      "Mit Mit\n",
      "seinen seinen\n",
      "Ideen Idee\n",
      "tritt tritt\n",
      "das der\n",
      "DRK DRK\n",
      "auch auch\n",
      "an an\n",
      "andere ander\n",
      "Fahrschulen Fahrschule\n",
      "in in\n",
      "der der\n",
      "Region Region\n",
      "heran heran\n",
      ". .\n",
      "Es ich\n",
      "gehe gehen\n",
      "darum darum\n",
      ", ,\n",
      "jetzt jetzt\n",
      "Erfahrungen Erfahrung\n",
      "zu zu\n",
      "sammeln sammeln\n",
      ", ,\n",
      "um um\n",
      "auf auf\n",
      "die der\n",
      "große groß\n",
      "Nachfrage Nachfrage\n",
      "vorbereitet vorbereiten\n",
      "zu zu\n",
      "sein mein\n",
      ", ,\n",
      "sagt sagen\n",
      "Sebastian Sebastian\n",
      "Mzyk Mzyk\n",
      ", ,\n",
      "Fahrdienstleiter Fahrdienstleiter\n",
      "beim beim\n",
      "DRK DRK\n",
      "Ostwestfalen-Lippe Ostwestfalen-Lippe\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Mahmood Mahmood\n",
      "Shaker Shaker\n",
      ", ,\n",
      "der der\n",
      "Iraker Iraker\n",
      ", ,\n",
      "hat haben\n",
      "beim beim\n",
      "Fragenbüffeln Fragenbüffeln\n",
      "für für\n",
      "die der\n",
      "Theorie Theorie\n",
      "und und\n",
      "bei bei\n",
      "der der\n",
      "Verständigung Verständigung\n",
      "mit mit\n",
      "dem der\n",
      "Fahrlehrer Fahrlehrer\n",
      "keine kein\n",
      "Sprachprobleme Sprachprobleme\n",
      ", ,\n",
      "obwohl obwohl\n",
      "er ich\n",
      "erst erst\n",
      "2014 2014\n",
      "nach nach\n",
      "Deutschland Deutschland\n",
      "gekommen kommen\n",
      "ist sein\n",
      ". .\n",
      "Er ich\n",
      "hat haben\n",
      "in in\n",
      "nur nur\n",
      "zehn zehn\n",
      "Monaten Monat\n",
      "Deutsch Deutsch\n",
      "gelernt lernen\n",
      ". .\n",
      "Im Im\n",
      "Irak Irak\n",
      "sieht sehen\n",
      "er ich\n",
      "für für\n",
      "sich sich\n",
      "keine kein\n",
      "Perspektive Perspektive\n",
      "mehr mehr\n",
      ". .\n",
      "Shakers Shakers\n",
      "Asylantrag Asylantrag\n",
      "ist sein\n",
      "anerkannt anerkennen\n",
      "worden werden\n",
      ", ,\n",
      "er ich\n",
      "möchte mögen\n",
      "in in\n",
      "Deutschland Deutschland\n",
      "bleiben bleiben\n",
      "und und\n",
      "so so\n",
      "bald bald\n",
      "wie wie\n",
      "möglich möglich\n",
      "arbeiten arbeiten\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "\" \"\n",
      "Vor Vor\n",
      "der der\n",
      "Ampel Ampel\n",
      "besser gut\n",
      "nicht nicht\n",
      "schalten schalen\n",
      "! !\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "Dirk Dirk\n",
      "Konert Konert\n",
      "während während\n",
      "der der\n",
      "Fahrstunde Fahrstunde\n",
      ". .\n",
      "\" \"\n",
      "Falls Fall\n",
      "sie ich\n",
      "umspringt umspringen\n",
      ". .\n",
      "Sonst Sonst\n",
      "wirst werden\n",
      "du du\n",
      "in in\n",
      "der der\n",
      "Prüfung Prüfung\n",
      "vielleicht vielleicht\n",
      "nervös nervös\n",
      ". .\n",
      "\" \"\n",
      "Dirk Dirk\n",
      "Konert Konert\n",
      "ist sein\n",
      "sich sich\n",
      "sicher sichern\n",
      ", ,\n",
      "dass dass\n",
      "Mahmood Mahmood\n",
      "die der\n",
      "praktische praktische\n",
      "Prüfung Prüfung\n",
      "bestehen bestehen\n",
      "kann können\n",
      ". .\n",
      "Wann Wann\n",
      "es ich\n",
      "so so\n",
      "weit weit\n",
      "ist sein\n",
      ", ,\n",
      "ist sein\n",
      "aber aber\n",
      "unklar unklar\n",
      ". .\n",
      "Denn denn\n",
      "Shaker Shaker\n",
      "fehlt fehlen\n",
      "Geld Geld\n",
      ". .\n",
      "Sein mein\n",
      "Arbeitslosengeld Arbeitslosengeld\n",
      "reicht reichen\n",
      "nicht nicht\n",
      "für für\n",
      "die der\n",
      "400 400\n",
      "Euro Euro\n",
      "Prüfungsgebühr Prüfungsgebühr\n",
      ", ,\n",
      "auch auch\n",
      "den der\n",
      "Theorieunterricht Theorieunterricht\n",
      "und und\n",
      "einige einig\n",
      "Fahrstunden Fahrstunden\n",
      "wird werden\n",
      "er ich\n",
      "noch noch\n",
      "zahlen zahlen\n",
      "müssen müssen\n",
      ". .\n",
      "Denn denn\n",
      "selbst selbst\n",
      "wer wer\n",
      "Auto Auto\n",
      "fahren fahren\n",
      "kann können\n",
      ", ,\n",
      "muss muss\n",
      "sich sich\n",
      "auf auf\n",
      "die der\n",
      "Prüfungsstrecke Prüfungsstrecke\n",
      "und und\n",
      "ihre mein\n",
      "Tücken Tücken\n",
      "vorbereiten vorbereiten\n",
      ". .\n",
      "Dirk Dirk\n",
      "Konert Konert\n",
      "rechnet rechnen\n",
      "mit mit\n",
      "Gesamtkosten Gesamtkosten\n",
      "von von\n",
      "über über\n",
      "1.500 1.500\n",
      "Euro Euro\n",
      "für für\n",
      "den der\n",
      "Iraker Iraker\n",
      ". .\n",
      "Vorerst Vorerst\n",
      "kann können\n",
      "Shaker Shaker\n",
      "die der\n",
      "Ausbildung Ausbildung\n",
      "deshalb deshalb\n",
      "nicht nicht\n",
      "fortsetzen fortsetzen\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Der der\n",
      "Fahrlehrer Fahrlehrer\n",
      "hofft hoffen\n",
      ", ,\n",
      "dass dass\n",
      "sein mein\n",
      "Schützling Schützling\n",
      "bald bald\n",
      "finanzielle finanzielle\n",
      "Unterstützung Unterstützung\n",
      "vom vom\n",
      "Jobcenter Jobcenter\n",
      "erhält erhalten\n",
      "– –\n",
      "die der\n",
      "Gespräche Gespräch\n",
      "laufen laufen\n",
      ". .\n",
      "Tatsächlich Tatsächlich\n",
      "kann können\n",
      "die der\n",
      "Arbeitsagentur Arbeitsagentur\n",
      "den der\n",
      "Erwerb Erwerb\n",
      "einer einer\n",
      "Fahrerlaubnis Fahrerlaubnis\n",
      "fördern fördern\n",
      ". .\n",
      "Die der\n",
      "Entscheidung Entscheidung\n",
      "treffe treffen\n",
      "im im\n",
      "Einzelfall Einzelfall\n",
      "die der\n",
      "Agentur Agentur\n",
      "vor vor\n",
      "Ort Ort\n",
      ", ,\n",
      "sagt sagen\n",
      "ein einen\n",
      "Sprecher Sprecher\n",
      ". .\n",
      "Wenn Wenn\n",
      "ein einen\n",
      "Führerschein Führerschein\n",
      "für für\n",
      "eine einen\n",
      "Arbeitsstelle Arbeitsstelle\n",
      "zwingend zwingen\n",
      "notwendig notwendig\n",
      "sei sein\n",
      ", ,\n",
      "könnten können\n",
      "eventuell eventuell\n",
      "auch auch\n",
      "alle all\n",
      "Kosten Kosten\n",
      "übernommen übernehmen\n",
      "werden werden\n",
      ". .\n",
      "Eine Eine\n",
      "Führerscheinförderung Führerscheinförderung\n",
      "speziell speziell\n",
      "für für\n",
      "Flüchtlinge Flüchtling\n",
      "gebe geben\n",
      "es ich\n",
      "aber aber\n",
      "nicht nicht\n",
      ", ,\n",
      "damit damit\n",
      "inländische inländische\n",
      "Bewerber Bewerber\n",
      "nicht nicht\n",
      "benachteiligt benachteiligen\n",
      "würden werden\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Auch Auch\n",
      "Gerhard Gerhard\n",
      "von von\n",
      "Bressensdorf Bressensdorf\n",
      "plädiert plädieren\n",
      "für für\n",
      "eine einen\n",
      "finanzielle finanzielle\n",
      "Gleichbehandlung Gleichbehandlung\n",
      "aller all\n",
      "sozial sozial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schwachen schwach\n",
      "Gruppen Gruppe\n",
      ". .\n",
      "Großen Großen\n",
      "Handlungsbedarf Handlungsbedarf\n",
      "sieht sehen\n",
      "er ich\n",
      "dagegen dagegen\n",
      "in in\n",
      "der der\n",
      "Bürokratie Bürokratie\n",
      ". .\n",
      "\" \"\n",
      "Viele viel\n",
      "Flüchtlinge Flüchtling\n",
      "haben haben\n",
      "auf auf\n",
      "der der\n",
      "Flucht Flucht\n",
      "ihre mein\n",
      "Papiere Papier\n",
      "verloren verlieren\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "er ich\n",
      ". .\n",
      "Ohne ohne\n",
      "amtlichen amtlich\n",
      "Ausweis Ausweis\n",
      "könne können\n",
      "man man\n",
      "aber aber\n",
      "keinen kein\n",
      "Führerschein Führerschein\n",
      "beantragen beantragen\n",
      ". .\n",
      "Es ich\n",
      "gebe geben\n",
      "Gespräche Gespräch\n",
      "mit mit\n",
      "den der\n",
      "Behörden Behörde\n",
      ", ,\n",
      "hier hier\n",
      "die der\n",
      "Hürden Hürde\n",
      "herabzusetzen herabsetzen\n",
      ". .\n",
      "Als als\n",
      "weitere weit\n",
      "Reaktion Reaktion\n",
      "auf auf\n",
      "die der\n",
      "vielen viel\n",
      "Flüchtlinge Flüchtling\n",
      "soll soll\n",
      "bald bald\n",
      "Arabisch Arabisch\n",
      "als als\n",
      "zwölfte zwölfte\n",
      "mögliche möglich\n",
      "Fremdsprache Fremdsprache\n",
      "in in\n",
      "der der\n",
      "Prüfung Prüfung\n",
      "zugelassen zulassen\n",
      "werden werden\n",
      ". .\n",
      "Die der\n",
      "Vorbereitungen Vorbereitung\n",
      "laufen laufen\n",
      ", ,\n",
      "bestätigt bestätigen\n",
      "der der\n",
      "TÜV TÜV\n",
      "Nord Nord\n",
      ", ,\n",
      "die der\n",
      "Entscheidung Entscheidung\n",
      "treffe treffen\n",
      "dann dann\n",
      "das der\n",
      "Verkehrsministerium Verkehrsministerium\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "DRK-Fahrlehrer DRK-Fahrlehrer\n",
      "Konert Konert\n",
      "würde werden\n",
      "gern gern\n",
      "noch noch\n",
      "einen ein\n",
      "Schritt Schritt\n",
      "weiter weit\n",
      "gehen gehen\n",
      ": :\n",
      "Vielleicht Vielleicht\n",
      "könne können\n",
      "ja ja\n",
      "bei bei\n",
      "der der\n",
      "Umschreibung Umschreibung\n",
      "von von\n",
      "Fahrerlaubnissen Fahrerlaubnis\n",
      "auf auf\n",
      "die der\n",
      "teure teuer\n",
      "Prüfung Prüfung\n",
      "verzichtet verzichten\n",
      "werden werden\n",
      ", ,\n",
      "wenn wenn\n",
      "der der\n",
      "Fahrlehrer Fahrlehrer\n",
      "das der\n",
      "Können Können\n",
      "des der\n",
      "Flüchtlings Flüchtling\n",
      "als als\n",
      "ausreichend ausreichen\n",
      "bewerte bewerten\n",
      ". .\n",
      "\" \"\n",
      "Bei Bei\n",
      "einer einer\n",
      "Beobachtungsfahrt Beobachtungsfahrt\n",
      "merke merken\n",
      "ich ich\n",
      "ja ja\n",
      "schnell schnellen\n",
      ", ,\n",
      "was was\n",
      "vorhanden vorhanden\n",
      "ist sein\n",
      "und und\n",
      "was was\n",
      "nicht nicht\n",
      ". .\n",
      "\" \"\n",
      "\n",
      "  \n",
      " \n",
      "Mit Mit\n",
      "solchen solch\n",
      "Ideen Idee\n",
      "tut tun\n",
      "sich sich\n",
      "Gerhard Gerhard\n",
      "von von\n",
      "Bressensdorf Bressensdorf\n",
      "schwer schwer\n",
      ". .\n",
      "Eine Eine\n",
      "vereinfachte vereinfachen\n",
      "Umschreibung Umschreibung\n",
      "von von\n",
      "Fahrerlaubnissen Fahrerlaubnis\n",
      "aus aus\n",
      "Nicht-EU-Staaten Nicht-EU-Staaten\n",
      "ist sein\n",
      "bisher bisher\n",
      "nur nur\n",
      "für für\n",
      "Länder Land\n",
      "möglich möglich\n",
      ", ,\n",
      "deren der\n",
      "Fahrausbildungsinhalte Fahrausbildungsinhalte\n",
      "in in\n",
      "Deutschland Deutschland\n",
      "gut gut\n",
      "bekannt bekennen\n",
      "sind sein\n",
      ", ,\n",
      "etwa etwa\n",
      "die der\n",
      "USA USA\n",
      ". .\n",
      "\" \"\n",
      "Die der\n",
      "arabischen arabisch\n",
      "Länder Land\n",
      "haben haben\n",
      "aber aber\n",
      "historisch historisch\n",
      "völlig völlig\n",
      "anders anders\n",
      "gewachsene gewachsene\n",
      "Verkehrssysteme Verkehrssysteme\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "von von\n",
      "Bressensdorf Bressensdorf\n",
      ". .\n",
      "In In\n",
      "Deutschland Deutschland\n",
      "wisse wissen\n",
      "man man\n",
      "etwa etwa\n",
      "über über\n",
      "die der\n",
      "syrische syrische\n",
      "Führerscheinprüfung Führerscheinprüfung\n",
      "so so\n",
      "gut gut\n",
      "wie wie\n",
      "nichts nichts\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Fares Fares\n",
      "Khalaf Khalaf\n",
      "hat haben\n",
      "diese dies\n",
      "Prüfung Prüfung\n",
      "vor vor\n",
      "einigen einig\n",
      "Jahren Jahr\n",
      "bestanden bestehen\n",
      ". .\n",
      "Der der\n",
      "22-Jährige 22-Jährige\n",
      "floh fliehen\n",
      "2013 2013\n",
      "aus aus\n",
      "Syrien Syrien\n",
      "und und\n",
      "besucht besuchen\n",
      "nun nun\n",
      "ebenfalls ebenfalls\n",
      "die der\n",
      "DRK-Fahrschule DRK-Fahrschule\n",
      ". .\n",
      "Die der\n",
      "Prüfungsstrecke Prüfungsstrecke\n",
      "in in\n",
      "seinem mein\n",
      "Heimatland Heimatland\n",
      "war sein\n",
      "etwa etwa\n",
      "50 50\n",
      "Meter Meter\n",
      "lang langen\n",
      ". .\n",
      "Khalaf Khalaf\n",
      "musste musste\n",
      "zwischen zwischen\n",
      "zwei zwei\n",
      "Hütchen Hütchen\n",
      "durchfahren durchfahren\n",
      "– –\n",
      "einmal einmal\n",
      "vorwärts vorwärts\n",
      "und und\n",
      "einmal einmal\n",
      "im im\n",
      "Rückwärtsgang Rückwärtsgang\n",
      ". .\n",
      "Verkehrsregeln Verkehrsregeln\n",
      "spielten spielen\n",
      "keine kein\n",
      "Rolle Rolle\n",
      ". .\n",
      "\" \"\n",
      "Es ich\n",
      "hängt hängen\n",
      "eher eher\n",
      "von von\n",
      "der der\n",
      "Familie Familie\n",
      "ab ab\n",
      ", ,\n",
      "wie wie\n",
      "man man\n",
      "dort dort\n",
      "fährt fahren\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "er ich\n",
      ". .\n",
      "\" \"\n",
      "Wenn Wenn\n",
      "der der\n",
      "Vater Vater\n",
      "sagt sagen\n",
      ": :\n",
      "›Fahr ›Fahr\n",
      "vorsichtig‹ vorsichtig‹\n",
      ", ,\n",
      "dann dann\n",
      "tut tun\n",
      "man man\n",
      "das der\n",
      ". .\n",
      "\" \"\n",
      "Khalaf Khalaf\n",
      "würde werden\n",
      "gern gern\n",
      "in in\n",
      "sein mein\n",
      "Land Land\n",
      "zurückkehren zurückkehren\n",
      ", ,\n",
      "wenn wenn\n",
      "der der\n",
      "Krieg Krieg\n",
      "vorbei vorbei\n",
      "ist sein\n",
      ". .\n",
      "Vorerst Vorerst\n",
      "arbeitet arbeiten\n",
      "er ich\n",
      "nun nun\n",
      "für für\n",
      "das der\n",
      "DRK DRK\n",
      ", ,\n",
      "das der\n",
      "deshalb deshalb\n",
      "einen ein\n",
      "Teil Teil\n",
      "seiner sich\n",
      "Führerscheinkosten Führerscheinkosten\n",
      "übernimmt übernehmen\n",
      ", ,\n",
      "in in\n",
      "einem einer\n",
      "Flüchtlingsheim Flüchtlingsheim\n",
      "in in\n",
      "Bielefeld Bielefeld\n",
      ". .\n",
      "\n",
      "  \n",
      " \n",
      "Während während\n",
      "Mahmood Mahmood\n",
      "Shakers Shakers\n",
      "Fahrstunde Fahrstunde\n",
      "sitzt sitzen\n",
      "Khalaf Khalaf\n",
      "auf auf\n",
      "der der\n",
      "Rückbank Rückbank\n",
      ". .\n",
      "\" \"\n",
      "Gilt Gilt\n",
      "hier hier\n",
      "immer immer\n",
      "Tempo Tempo\n",
      "50 50\n",
      ", ,\n",
      "wenn wenn\n",
      "es ich\n",
      "kein kein\n",
      "Schild Schild\n",
      "gibt geben\n",
      "? ?\n",
      "\" \"\n",
      ", ,\n",
      "fragt fragen\n",
      "er ich\n",
      "nach nach\n",
      "vorne vorne\n",
      ". .\n",
      "\" \"\n",
      "Genau Genau\n",
      "\" \"\n",
      ", ,\n",
      "sagt sagen\n",
      "Fahrlehrer Fahrlehrer\n",
      "Konert Konert\n",
      ", ,\n",
      "\" \"\n",
      "in in\n",
      "der der\n",
      "Stadt Stadt\n",
      "immer immer\n",
      ". .\n",
      "Aber aber\n",
      "es ich\n",
      "gibt geben\n",
      "kein kein\n",
      "Recht Recht\n",
      "auf auf\n",
      "die der\n",
      "Höchstgeschwindigkeit Höchstgeschwindigkeit\n",
      ". .\n",
      "Immer Immer\n",
      "auf auf\n",
      "die der\n",
      "anderen ander\n",
      "Autos Auto\n",
      "achten achten\n",
      ". .\n",
      "\" \"\n",
      "Vor Vor\n",
      "und und\n",
      "hinter hinter\n",
      "dem der\n",
      "Fahrschulwagen Fahrschulwagen\n",
      "fahren fahren\n",
      "nun nun\n",
      "immer immer\n",
      "mehr mehr\n",
      "andere ander\n",
      "Autos Auto\n",
      ", ,\n",
      "es ich\n",
      "ist sein\n",
      "dunkel dunkeln\n",
      "geworden werden\n",
      ", ,\n",
      "die der\n",
      "Pendler Pendler\n",
      "wollen wollen\n",
      "nach nach\n",
      "Hause Haus\n",
      ". .\n",
      "Mahmood Mahmood\n",
      "Shaker Shaker\n",
      "schweigt schweigen\n",
      "und und\n",
      "steuert steuern\n",
      "das der\n",
      "Auto Auto\n",
      "sicher sichern\n",
      "durch durch\n",
      "den der\n",
      "Bielefelder Bielefelder\n",
      "Feierabendverkehr Feierabendverkehr\n",
      ", ,\n",
      "einer einer\n",
      "Zukunft Zukunft\n",
      "in in\n",
      "Deutschland Deutschland\n",
      "entgegen entgegen\n",
      ". .\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = t\n",
    "doc = nlp(text)\n",
    "\n",
    "#for token in doc:\n",
    "    #print(token, token.pos_, token.tag_)\n",
    "    \n",
    "#for token in doc:\n",
    "    #print(token, token.morph)\n",
    "    \n",
    "for token in doc:\n",
    "    print(token, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "established-insertion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)\n",
    "#type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "wired-christian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7ff2c1394c50>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7ff2c13db470>), ('morphologizer', <spacy.pipeline.morphologizer.Morphologizer object at 0x7ff2c13dbef0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7ff2c10f2ec0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7ff2c11606e0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7ff2c1383c80>), ('lemmatizer', <spacy.pipeline.lemmatizer.Lemmatizer object at 0x7ff2c1408910>)]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "intellectual-sixth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machen machen\n",
      ", ,\n",
      "mache machen\n",
      ", ,\n",
      "machst machen\n",
      ", ,\n",
      "macht machen\n",
      ", ,\n",
      "machte machen\n",
      ", ,\n",
      "gemacht machen\n"
     ]
    }
   ],
   "source": [
    "with nlp.select_pipes(enable=\"lemmatizer\"):\n",
    "    doc = nlp(\"machen, mache, machst, macht, machte, gemacht\")\n",
    "for t in doc:\n",
    "    print(t, t.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "arctic-sucking",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy_sentiws.spaCySentiWS object at 0x7ff2b9e18950> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c22247ec71a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msentiws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaCySentiWS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiws_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/emilymartin/Documents/data/SentiWS_v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Die Dummheit der Unterwerfung blüht in hübschen Farben.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy_sentiws.spaCySentiWS object at 0x7ff2b9e18950> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "from spacy_sentiws import spaCySentiWS\n",
    "from spacy.language import Language\n",
    "\n",
    "#nlp = spacy.load('de_core_news_sm')\n",
    "sentiws = spaCySentiWS(sentiws_path='/Users/emilymartin/Documents/data/SentiWS_v2')\n",
    "\n",
    "nlp.add_pipe(sentiws)\n",
    "doc = nlp('Die Dummheit der Unterwerfung blüht in hübschen Farben.')\n",
    "\n",
    "for token in doc:\n",
    "    print('{}, {}, {}'.format(token.text, token._.sentiws, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-delivery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
