{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earned-newsletter",
   "metadata": {},
   "source": [
    "## Junge Freiheit\n",
    "#### Code for scraping Junge Freiheit\n",
    "- https://jungefreiheit.de\n",
    "\n",
    "- NOTE: This script can be tempermental, due to changes on their end it began picking up articles form 2014. I could not figure out how to fix this, I apologize. I used a quick fix and just chopped the rows I didn't need off the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opening-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advisory-fancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "# Using two keywords (\"migraten\" and \"flüchtling\") this time because this is a smaller newspaper with less articles\n",
    "search_f = '/?s=fl%C3%BCchtling'\n",
    "base_url = 'https://jungefreiheit.de/page/'\n",
    "n = 2 # I started at 2 because the structure of the url is different for page 1 and there is no reason I would need\n",
    "# it searching for 2015\n",
    "\n",
    "#Compile urls \n",
    "urls_f = []\n",
    "while n <= 39:\n",
    "    url_f = base_url+str(n)+search_f\n",
    "    n += 1\n",
    "    urls_f.append(url_f)\n",
    "    \n",
    "print(len(urls_f))\n",
    "\n",
    "# Search using keyword: Migranten\n",
    "search_m = '/?s=migranten'\n",
    "urls_m = []\n",
    "m = 2\n",
    "while m <= 149:\n",
    "    url_m = base_url+str(m)+search_m\n",
    "    m += 1\n",
    "    urls_m.append(url_m)\n",
    "    \n",
    "print(len(urls_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comfortable-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "#Create one list of urls\n",
    "urls = urls_m +urls_f\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuffed-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the urls of the pages of articles and if the date is 2015 get the links for the relevent articles\n",
    "\n",
    "art_links = []\n",
    "date = []\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    d = soup.find(\"span\", {\"class\":\"elementor-post-date\"})\n",
    "    if d.text[-6:-2]=='2015':\n",
    "        date.append(d.text)\n",
    "        divs = soup.find_all(\"div\", {\"class\":\"elementor-post__text\"})\n",
    "        for div in divs:\n",
    "            a = div.find('a')\n",
    "            art_links.append(a.get('href'))\n",
    "            \n",
    "        \n",
    "#art_links                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "friendly-university",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a little sparse, but it is a smaller weekly newspaper\n",
    "len(art_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recent-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each link and get the date and text and append to a dictionary\n",
    "date_dict = {}\n",
    "art_dict_jf = {}\n",
    "x = ' '\n",
    "for link in art_links:\n",
    "    page = urllib.request.urlopen(link)\n",
    "    soup = BeautifulSoup(page)\n",
    "    t = soup.find(\"div\", {\"class\":\"elementor-widget-theme-post-content\"})\n",
    "    #print(t)\n",
    "    paras = t.findAll('p')\n",
    "    a = [p.text for p in paras]\n",
    "    d = soup.find(\"span\", {\"class\":\"elementor-icon-list-text elementor-post-info__item elementor-post-info__item--type-date\"})\n",
    "    text = x.join(a)\n",
    "    date_dict[link] = d.text\n",
    "    art_dict_jf[link] = text\n",
    "    #print(text)\n",
    "    \n",
    "#art_dict_jf\n",
    "#date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acceptable-arbitration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I guess there were 3 duplicates\n",
    "len(art_dict_jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swedish-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframe from the dictionaries\n",
    "df_jf = pd.DataFrame.from_dict(art_dict_jf, orient='index')\n",
    "df_jf.reset_index(inplace=True)\n",
    "df_jf.columns = ['href', 'text']\n",
    "df_jf['date']= df_jf['href'].map(date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "governing-application",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>toks</th>\n",
       "      <th>types</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://jungefreiheit.de/kultur/gesellschaft/2...</td>\n",
       "      <td>Um ihn herum hängen Arbeiter gerade die Weihna...</td>\n",
       "      <td>19. November 2015</td>\n",
       "      <td>1348</td>\n",
       "      <td>77</td>\n",
       "      <td>1569</td>\n",
       "      <td>658</td>\n",
       "      <td>0.419375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>POTSDAM. Brandenburgs AfD-Chef Alexander Gaula...</td>\n",
       "      <td>18. November 2015</td>\n",
       "      <td>385</td>\n",
       "      <td>20</td>\n",
       "      <td>456</td>\n",
       "      <td>281</td>\n",
       "      <td>0.616228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://jungefreiheit.de/debatte/kommentar/201...</td>\n",
       "      <td>Die Norwegerin Linda Hagen ist immer noch ganz...</td>\n",
       "      <td>05. November 2015</td>\n",
       "      <td>171</td>\n",
       "      <td>7</td>\n",
       "      <td>203</td>\n",
       "      <td>152</td>\n",
       "      <td>0.748768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>ERFURT. Asylbewerber, die mit der Deutschen Ba...</td>\n",
       "      <td>04. November 2015</td>\n",
       "      <td>191</td>\n",
       "      <td>12</td>\n",
       "      <td>227</td>\n",
       "      <td>157</td>\n",
       "      <td>0.691630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://jungefreiheit.de/politik/ausland/2015/...</td>\n",
       "      <td>TRIPOLIS. Der libysche „Allgemeine Volkskongre...</td>\n",
       "      <td>04. November 2015</td>\n",
       "      <td>262</td>\n",
       "      <td>17</td>\n",
       "      <td>307</td>\n",
       "      <td>181</td>\n",
       "      <td>0.589577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href  \\\n",
       "0  https://jungefreiheit.de/kultur/gesellschaft/2...   \n",
       "1  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "2  https://jungefreiheit.de/debatte/kommentar/201...   \n",
       "3  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "4  https://jungefreiheit.de/politik/ausland/2015/...   \n",
       "\n",
       "                                                text               date  \\\n",
       "0  Um ihn herum hängen Arbeiter gerade die Weihna...  19. November 2015   \n",
       "1  POTSDAM. Brandenburgs AfD-Chef Alexander Gaula...  18. November 2015   \n",
       "2  Die Norwegerin Linda Hagen ist immer noch ganz...  05. November 2015   \n",
       "3  ERFURT. Asylbewerber, die mit der Deutschen Ba...  04. November 2015   \n",
       "4  TRIPOLIS. Der libysche „Allgemeine Volkskongre...  04. November 2015   \n",
       "\n",
       "   word_count  sent_count  toks  types       TTR  \n",
       "0        1348          77  1569    658  0.419375  \n",
       "1         385          20   456    281  0.616228  \n",
       "2         171           7   203    152  0.748768  \n",
       "3         191          12   227    157  0.691630  \n",
       "4         262          17   307    181  0.589577  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding columns\n",
    "word_c = df_jf.text.str.split().map(len)\n",
    "df_jf['word_count'] = word_c\n",
    "df_jf['sent_count'] = df_jf['text'].map(lambda s: len(nltk.sent_tokenize(s))) \n",
    "df_jf['toks'] = df_jf['text'].map(lambda t: len(nltk.word_tokenize(t))) \n",
    "df_jf['types'] = df_jf['text'].map(lambda x: len(set(nltk.word_tokenize(x)))) \n",
    "df_jf['TTR'] = df_jf.types/df_jf.toks\n",
    "df_jf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dental-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>toks</th>\n",
       "      <th>types</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://jungefreiheit.de/debatte/kommentar/201...</td>\n",
       "      <td>Es ist leicht, den moralisch überlegenen Wohlt...</td>\n",
       "      <td>15. Mai 2015</td>\n",
       "      <td>766</td>\n",
       "      <td>28</td>\n",
       "      <td>885</td>\n",
       "      <td>449</td>\n",
       "      <td>0.507345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>KÖLN. Der Präsident des Zentralverbands des De...</td>\n",
       "      <td>04. Mai 2015</td>\n",
       "      <td>209</td>\n",
       "      <td>15</td>\n",
       "      <td>247</td>\n",
       "      <td>157</td>\n",
       "      <td>0.635628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>BERLIN. Der Direktor des Instituts der deutsch...</td>\n",
       "      <td>27. April 2015</td>\n",
       "      <td>249</td>\n",
       "      <td>15</td>\n",
       "      <td>308</td>\n",
       "      <td>175</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>https://jungefreiheit.de/debatte/kommentar/201...</td>\n",
       "      <td>Die Reaktionen aus Brüssel und Berlin auf die ...</td>\n",
       "      <td>25. April 2015</td>\n",
       "      <td>780</td>\n",
       "      <td>36</td>\n",
       "      <td>900</td>\n",
       "      <td>476</td>\n",
       "      <td>0.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https://jungefreiheit.de/politik/deutschland/2...</td>\n",
       "      <td>BERLIN. In Berlin ist ein Flüchtling aus dem I...</td>\n",
       "      <td>09. Februar 2015</td>\n",
       "      <td>193</td>\n",
       "      <td>13</td>\n",
       "      <td>213</td>\n",
       "      <td>136</td>\n",
       "      <td>0.638498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 href  \\\n",
       "71  https://jungefreiheit.de/debatte/kommentar/201...   \n",
       "72  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "73  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "74  https://jungefreiheit.de/debatte/kommentar/201...   \n",
       "75  https://jungefreiheit.de/politik/deutschland/2...   \n",
       "\n",
       "                                                 text              date  \\\n",
       "71  Es ist leicht, den moralisch überlegenen Wohlt...      15. Mai 2015   \n",
       "72  KÖLN. Der Präsident des Zentralverbands des De...      04. Mai 2015   \n",
       "73  BERLIN. Der Direktor des Instituts der deutsch...    27. April 2015   \n",
       "74  Die Reaktionen aus Brüssel und Berlin auf die ...    25. April 2015   \n",
       "75  BERLIN. In Berlin ist ein Flüchtling aus dem I...  09. Februar 2015   \n",
       "\n",
       "    word_count  sent_count  toks  types       TTR  \n",
       "71         766          28   885    449  0.507345  \n",
       "72         209          15   247    157  0.635628  \n",
       "73         249          15   308    175  0.568182  \n",
       "74         780          36   900    476  0.528889  \n",
       "75         193          13   213    136  0.638498  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When I re-ran something went wrong and there were articles from dates I didnt want... getting rid of those\n",
    "n = 19\n",
    "df_jf.drop(df_jf.tail(n).index,\n",
    "        inplace = True)\n",
    "df_jf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accomplished-mention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76 entries, 0 to 75\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   href        76 non-null     object \n",
      " 1   text        76 non-null     object \n",
      " 2   date        76 non-null     object \n",
      " 3   word_count  76 non-null     int64  \n",
      " 4   sent_count  76 non-null     int64  \n",
      " 5   toks        76 non-null     int64  \n",
      " 6   types       76 non-null     int64  \n",
      " 7   TTR         76 non-null     float64\n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_jf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baking-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling\n",
    "pd.to_pickle(df_jf, \"jf_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
